随着业务规模的扩展，业务的数据量急剧增长，随之带来的是存储压力以及查询压力，对数据库的存储资源以及计算资源提出了更高的要求。传统的单机数据库模式已经不能满足需求，
而基于分布式文件系统的共享数据库正是能满足此场景。


PostgreSQL单机数据库主备模式：

    主备机相对独立，拥有各自的物理存储，通过XLog进行数据同步；当单节点存储达到瓶颈时，无法进行扩容。
    备机可对外提供查询，当单备机查询压力较大时，可扩展备机。扩展备机可以提供计算资源，同时也增加了数据的备份，浪费存储资源。
 

基于分布式文件系统(cephfs)的共享PostgreSQL模式：

    计算资源和存储资源相对独立，可分别进行扩展；且扩展对业务无感知。
    可通过接口层实现读写分离，以及负载均衡。
    使用并行逻辑，提升整体OLAP性能。  

逻辑层

主机负责接受写请求，并将XLog日志同步给备机。这里日志同步存在一些不同，单机模式主机需要同步所有XLog日志内容，备机接收XLog之后进行落盘，然后在读取XLog，进行重做，恢复数据。

在共享模式下，由于数据是共享的，主机只需要同步XLog的地址，也就是LSN给备机，备机根据LSN直接读取XLog内容，然后进行重做，恢复数据。减少了主备之间的网络流量，缩短备机恢复数据的流程。



备机负责读请求，需要保证备机的shared_buffer中数据尽可能是热数据，备机需要快速重做XLog日志以保持与主机同步。单机模式备机只有一个startup进程进行XLog读取，以及重做；
在主机有大量写入的情况下，备机重做往往不能及时响应。


 为了加速备机重做，将startup进程的工作进行拆分，分成XLog读取和XLog重做两部分，这两部分工作分别由子进程Reader和worker负责，startup只需要负责任务的调度以及分发
 。Reader进行XLog预读取，读取尽可能多的XLog并放入到XLogBuffer中；startup负责从XLogBuffer中读取XLogRecord，然后根据XLogRecord内容进行分发。
 这里分发的原则是将对不同的表或者索引等数据信息修改的XLog分发给不同的worker，每个表始终都会由同一个worker进行数据恢复，worker之间的并行是表级别的，保证数据一致性。



使用worker并行重做XLog日志后，性能得到明显提升



备机除了应对热数据的快速查询以外，还要对某些冷数据的查询进行响应。由于备机的数据都是恢复在内存中，冷数据需要去磁盘读取。PostgreSQL对数据的修改会优先放在内存中，只是将XLog确定写盘，。待到checkpoint时再将脏数据写入磁盘。所以当备机去磁盘读取冷数据的时候，这部分冷数据的最新版本也许并没有被主机写盘，备机读取的数据则不是最新的数据。

为了保证读取数据的最终一致性，备机里面保存了XLog对page的修改信息，就是从最近一次checkpoint之后，记录都有那些XLog（LSN）修改过那些page，这些信息存放在hash表中，便于查询。当读取一个page时，以page信息作为hashkey去查询，找到page的修改LSN列表，查看当前page的LSN；如果当前LSN已经是最新的，page就是最新的；否则，从当前LSN开始，使用XLog对page进行恢复，直到最新。这里对page的数据恢复由查询进程负责，每个进程都会去访问hash表，为了不影响并发，对hash表采用了逻辑分区。每个进程根据要访问的page计算hash值，再根据hash值计算出属于哪个逻辑分区，然后在逻辑分区上加锁，有效避免了大并发下的长时间阻塞。



接口层

接口层主要负责读写分离，以及负载均衡。读写分离需要先对SQL进行一次词法解析，然后根据解析的类型进行SQL分发；DML/DDL发送给主节点，查询经过负载均衡发送给备机。



存储层

这里将CEPH简单地当做磁盘使用，数据库没有与存储有任何耦合；后续会考虑将数据库部分功能下推到CEPH中去做，比如数据库的日志重做功能，使得备机只需要去读取需要的数据，不再需要进行数据恢复，进一步提升性能。

 

基于分布式文件系统的PostgreSQL，将存储资源与计算资源进行隔离，存储可以突破单机的瓶颈，计算资源可以独立进行扩展，可满足现在单机无法应对的业务
